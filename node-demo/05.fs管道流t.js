var fs = require('fs');

// // 创建读取流
// // 每读取64k的时候，就调用回调函数  ，触发data事件
// var rs = fs.createReadStream('./a副本2.png');

// var temp = '';
// // var count = 1; //计数器
// rs.on('data',function(chunk){
//     // console.log(chunk);
//     // console.log(count++);
//     temp += chunk;
// })

// // 管道流读取完毕的时候，触发end事件
// rs.on('end',function(){
//     console.log(temp);
// })



// 通过流写入数据
// var ws = fs.createWriteStream('./hello1.txt');
// ws.write('一只乌鸦口渴了aaaa');



var rs = fs.createReadStream('./hello1.txt');
var ws = fs.createWriteStream('./hello1副本.txt');

// var n = 0;
// rs.on('data',function(chunk){
//     ws.write(chunk);
//     n++;
// })
// rs.on('end',function(){
//     console.log('读写完毕'+n);
// })
// 这个方法有一个弊端，
// 就是读文件的效率比写文件的效率高
// 内存消耗大


// pipe方法写入数据是，
// 等当前读出的数据全部写入后，才进行下一次的读取操作。
// 内存利用非常充分，但是读写时间比较长。
rs.pipe(ws);


// 1.传统文件读写
// 2.管道流读写

// 1.传统文件读写操作，这种读写是普通读写。
// 读写效率非常高，但是内存利用特别特别低的传统读写操作。
// 读文件，写文件，还有就是文件的复制

// 2.管道流，管道流也是读写文件的，
// 只不过这个管道流要比传统普通读写性能，要强大得多
// 虽然它在读写时间上来说，不太好
// 时间方面，要比直接读写要耗损
// 但是在内存利用率上是直接要高很多的
// 

// 举个例子：大家都知道大数据吧！
// 其实，那个大数据的本质是什么？
// 本质就是我收集无穷大的数据
// 我写一个爬虫，在网络上所有，
// 我感兴趣的数据，全爬下来
// 爬下来，那么就会涉及到，我爬下来的数据，
// 要加载性能的时候，
// 我要一条一条数据分析数据
 

// 如果按照传统文件读取方式，
// 把爬下来的数据，加载进内存话

// 传统读写的弊端是什么呢？
// 我必须要把所有的数据，一次性的全部加载到内存
// 之后，我才能进行下一步操作

// 那，网络上爬下来的数据，那不是按照G来计算的。
// 那是按照兆G来算的，那个数据非常非常大
// 你生产的，内存性能再强，顶多顶到256G
// 服务器端内存，达到256G内存，已经很了不起了
// 不能再往上去加了
// 那256G跟网络上海量的数据比，
// 256G内存也不够你用，

// 所以我们就想到了管道流
// 管道流,是怎么读取数据的呢
// 它是分片段读取的,
// 每一次,它只读64k的数据,
// 每一次只读64千字节的数据,
// 你读完这64千字节的数据,
// 好你就可以处理这个数据了,

// 那么这样我们就可以把,海量的数据,
// 分割成若干个64千字节的块
// 一次性,只要处理完这个64k的数据,
// 是不是就可以处理下一个数据64k字节了,

// 这就是管道流

// 管道流现在主要运用在大数据的数据处理上
// 这个是一个方向,
// 还有一个方向就是跟我们web服务器相关的
// 就是服务器想要把某个,本地静态文件,
// 发给前端，我们使用的就是管道流来发的

// 还有一个问题，
// 我们往服务器端发送数据，一种叫做get数据，一种叫做post数据。
// get,直接把你的参数拼接到url之后
// post里面的参数，直接塞进http请求头里面了。

// 数据包分为：包头，包身，包尾。
// 包头：如果你发的是http请求的话，那
// 么包头里面的东西就是你发的http请求参数
// 包身体里面的，就是你发的内容。
// 包尾里面是你的，校验段

// http是基于tcp协议的，
// tcp又是面向链接的，
// 面向连接有什么特征呢？
// 就是你的数据丢了，丢了，我知道数据丢了，
// 它怎么知道数据丢了，就靠http请求报文的那个包尾
// 包尾的有校验段，
// 如果对端，没有收到这个校验段，或者说这个校验段编码出问题的话
// 那么它就认为你这个包丢了，就会让你从服务器重新发一遍

// 这就是http分成的三大段

// 而我们的post请求就是放到http请求报文的头部，
// 报头是怎么去发送的呢

// 换个问题，我们向后台发数据，或者发大文件的时候

// 我们都使用post来发

// 做过这种需求的，特别是发这种图片过去
// 为什么使用post而不是用get呢？

// get数据发送数据的时候是把参数拼接到url之后
// 而服务器是对你的url是有限制的
// 服务器能接收到的url参数一般是256个字符，一般它只收256个字符，
// 但是这个数据宽度是可调的

// 最多能调到两千个字符宽度
// 但是，没人这么干，因为如果说你把字符调成两千宽度的话
// 第一，你发的数据并没有大多少，
// 第二，因为你这个请求长了，可能会导致请求截断
// 如果请求被截断的话
// 你后台还得去拼接，无形中增大后台的压力
// 那就是说，你发的数据，后台值拼接，256个字符

// 256个字符能表示多少信息？
// 一个字符按照一个整型数来算
// 那也是256乘以2kb，
// 那也没有多少，也就那几兆
// 一次性只能提交几兆的文件

// 但是我们往后台发，包括你上传影片
// 那不是按兆来传的，那都是按GB来传的
// 那你一次性只传几kb你怎么传？
// 那只能用post去传，
// 那post 为什么能够发送大数据呢？
// 是因为post在提交数据的时候
// 用的也是管道流技术

// 管道流技术，知道是怎么读取数据的把一个大文件
// 切成若干个64k的小文件
// 一次发64k一次发64k，不管你多大的文件都切成64k的小文件
// 蚂蚁搬家的形式，一次一次的发送数据，
// 是不是不管你多大个数据，都能给你发送过去

// 而后台，怎么做，
// 后台只需要在接收流，里面等着它，传进来64k，就拼接64k
// 什么时候传完你就什么时候拼接完

// 你就可以拿到一个完整的视频信息
// 然后你就可以把这些信息往本地磁盘去写入
// 这就是管道流
// 前端用post方法往后台发送数据的时候就是用管道流来发送
// 后台向前端发送数据呢
// 前端可以往后台发送数据，提交大数据
// 后台是不是也可以向前端发送数据


// 举个简单的例子：比如说视频网站，
// 视频网站，是不是在后台不断的往前端发送数据
// 发送视频信息
// 现在大部分视频网站用的都是流媒体
// 流体体技术，就不说它了，

// 倒退到零几年的时候，那时候流媒体还没有发展起来
// 那个时候是怎么发送数据的
// 用得也是管道流技术
// 我们把视频信息一小段一小段的给你发送到前端

// 给你发送一部分，前端你解析一部分
// 这样是不是就可以做到边下载边播放这项技术了
// 还记得迅雷那个技术吧
// 早些时候，你下载视频，只有你完整下完之后才能播放
// 但是最新的，零几年迅雷出现的新技术，
// 你可以先下载，等视频下载差不多的时候，就可以播放了

// 这个是怎么回事，这个就是使用管道流。
// 其实发送第一个64k视频，就可以给你播放了，只不过是保证用户体验
// 让后台多发送几个64k让线程有个缓冲，保证用户体验。

// 以上是管道流的应用

// 我们学管道流技术的应用是：
// 第一，我们通过post方法，向后台提交数据，在后台我么用管道流接收数据
// 第二，我们要向前端发文件，我们需要使用管道流去向前端去发

// 这个是fs模块的三大知识点
